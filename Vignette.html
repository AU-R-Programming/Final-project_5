<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>logisticreg</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">logisticreg</h1>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Logistic regression is a widely used statistical method for modeling
binary outcomes based on one or more predictor variables. The
<code>logisticreg</code> package provides a streamlined and robust
framework for performing logistic regression using numerical
optimization. This package is designed to help users estimate model
parameters, quantify uncertainty through bootstrap confidence intervals,
and evaluate model performance using comprehensive metrics.</p>
<div id="key-features-of-logisticreg" class="section level3">
<h3>Key Features of <code>logisticreg</code></h3>
<ul>
<li><p><strong>Parameter Estimation</strong>: Uses numerical
optimization (via the <code>optim</code> function) to estimate logistic
regression coefficients efficiently.</p></li>
<li><p><strong>Bootstrap Confidence Intervals</strong>: Provides a
non-parametric approach to assess the uncertainty of estimated
coefficients.</p></li>
<li><p><strong>Prediction</strong>: Includes functions for predicting
probabilities and binary outcomes based on fitted models.</p></li>
<li><p><strong>Performance Evaluation</strong>: Offers tools to
calculate confusion matrices and key performance metrics, such as
accuracy, sensitivity, specificity, and diagnostic odds ratios.</p></li>
</ul>
</div>
<div id="why-use-logisticreg" class="section level3">
<h3>Why Use <code>logisticreg</code>?</h3>
<ul>
<li><p><strong>Customizable Workflows</strong>: Users can easily
integrate their own data and apply the package to various binary
classification tasks.</p></li>
<li><p><strong>Lightweight and Flexible</strong>: Built for R users who
need a quick and effective solution for logistic regression without
relying on large external dependencies.</p></li>
<li><p><strong>Educational Value</strong>: Ideal for understanding
logistic regression concepts and applying them to real-world
datasets.</p></li>
</ul>
<p>This vignette demonstrates the step-by-step use of the
<code>logisticreg</code> package, from estimating coefficients to
evaluating model performance, using a synthetic dataset.</p>
</div>
<div id="how-to-use-this-vignette" class="section level3">
<h3>How to Use This Vignette</h3>
<p>This vignette provides:</p>
<ol style="list-style-type: decimal">
<li><p>A <strong>workflow example</strong> showing the usage of the
package functions on a synthetic dataset.</p></li>
<li><p>Explanations of the key functions included in the
package.</p></li>
<li><p>Insights into interpreting the outputs and evaluating model
performance.</p></li>
</ol>
<p>By the end of this vignette, you’ll have a comprehensive
understanding of how to:</p>
<ol style="list-style-type: decimal">
<li><p>Fit a logistic regression model.</p></li>
<li><p>Interpret the results.</p></li>
<li><p>Evaluate the model’s predictive accuracy and
reliability.</p></li>
</ol>
</div>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>To install the <code>logisticreg</code> package, use the following
command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;AU-R-Programming/Final-project_5/logisticreg&quot;</span>)</span></code></pre></div>
<p>Load the package after installation:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">library</span>(logisticreg)</span></code></pre></div>
<div id="example-workflow" class="section level3">
<h3><strong>3. Example Workflow</strong></h3>
<p>We will demonstrate the functionality of the package with an example
workflow using the Bank dataset provided.</p>
<div id="information-about-dataset" class="section level5">
<h5>Information about dataset</h5>
<p>The data is related with direct marketing campaigns of a Portuguese
banking institution. The marketing campaigns were based on phone calls.
Often, more than one contact to the same client was required, in order
to access if the product (bank term deposit) would be (‘yes’) or not
(‘no’) subscribed. The classification goal is to predict if the client
will subscribe a term deposit (variable y).</p>
<p>You can access the data from the <a href="https://archive.ics.uci.edu/dataset/222/bank+marketing">UC Irvine
Machine Learning Repository</a></p>
<p><strong>Step 1: Load the dataset, you can change the path to where
the data is saved</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;~/Downloads/bank.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;;&quot;</span>)</span></code></pre></div>
<p>Convert target variable to binary (0 = “no”, 1 = “yes”)</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>data<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(data<span class="sc">$</span>y <span class="sc">==</span> <span class="st">&quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<p>Select the desired columns/predictors you wish to use and create a
subset of the data. Here we used</p>
<ul>
<li>age: clients age</li>
<li>balance: average yearly balance</li>
<li>duration: last contact duration, in seconds (numeric).</li>
<li>previous: number of contacts performed before this campaign and for
this client</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>numerical_columns <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;balance&quot;</span>, <span class="st">&quot;duration&quot;</span>, <span class="st">&quot;previous&quot;</span>)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>data_subset <span class="ot">&lt;-</span> data[, <span class="fu">c</span>(numerical_columns, <span class="st">&quot;y&quot;</span>)]</span></code></pre></div>
<p>Standardize numerical features (mean = 0, sd = 1) Standardizing
features is a best practice in logistic regression, especially when
features vary in scale, and it often results in a more effective and
interpretable model.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>X_numeric <span class="ot">&lt;-</span> <span class="fu">scale</span>(data_subset[, numerical_columns])</span></code></pre></div>
<p>Add intercept column to the design matrix Including an intercept
column is essential for most regression problems, ensuring the model
captures the underlying structure and relationships in the data
effectively.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(<span class="dv">1</span>, X_numeric))</span></code></pre></div>
<p>Ensure the response variable (y) is numeric</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(data_subset<span class="sc">$</span>y)</span></code></pre></div>
<p>Here:</p>
<ul>
<li>X is the design matrix including an intercept term.?</li>
<li>y is the binary response variable.</li>
</ul>
<p><strong>Step 2: Estimate Coefficients</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> <span class="fu">estimate_beta</span>(X, y)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">&quot;Estimated Coefficients:&quot;</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Estimated Coefficients:&quot;</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>  <span class="fu">print</span>(beta)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co">#&gt;                 [,1]</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">#&gt;          -2.36420142</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a><span class="co">#&gt; age       0.14571952</span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="co">#&gt; balance   0.07427082</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="co">#&gt; duration  0.93574900</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="co">#&gt; previous  0.26981146</span></span></code></pre></div>
<p><strong>Step 3: Compute Bootstrap Confidence Intervals</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a> bootstrap_results <span class="ot">&lt;-</span> <span class="fu">bootstrap_co_int</span>(X, y)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">&quot;Bootstrap Confidence Intervals:&quot;</span>)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Bootstrap Confidence Intervals:&quot;</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>  <span class="fu">print</span>(bootstrap_results)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">#&gt; $lower</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">#&gt; [1] -2.41964646  0.06222908  0.04182974  0.76875427  0.19777794</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">#&gt; $upper</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">#&gt; [1] -2.2576157  0.2205504  0.1178402  1.0055004  0.3396779</span></span></code></pre></div>
<p><strong>Step 4: Predict Probabilities</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>pred_probs <span class="ot">&lt;-</span> <span class="fu">predicted_prob</span>(beta, X)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="fu">head</span>(pred_probs)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a><span class="co">#&gt;            [,1]</span></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co">#&gt; [1,] 0.03691217</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co">#&gt; [2,] 0.11907917</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co">#&gt; [3,] 0.06522439</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co">#&gt; [4,] 0.05534907</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co">#&gt; [5,] 0.08495987</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co">#&gt; [6,] 0.07466346</span></span></code></pre></div>
<p><strong>Step 5: Predict Class Labels</strong> Predict the class
labels using the predict function with a default cutoff of 0.5:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(beta, X)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">head</span>(predictions)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="co">#&gt;      [,1]</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="co">#&gt; [1,]    0</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="co">#&gt; [2,]    0</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a><span class="co">#&gt; [3,]    0</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a><span class="co">#&gt; [4,]    0</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="co">#&gt; [5,]    0</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a><span class="co">#&gt; [6,]    0</span></span></code></pre></div>
<ul>
<li>Observations with probabilities greater than the cutoff are
classified as 1, otherwise as 0.</li>
<li>The output is a binary vector of predicted class labels.</li>
</ul>
<p><strong>Step 6: Evaluate Model Performance</strong></p>
<ul>
<li>Evaluate the model’s performance using the confusion_matrix_metrics
function:</li>
</ul>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>metrics <span class="ot">&lt;-</span> <span class="fu">confusion_matrix_metrics</span>(y, predictions)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">&quot;Confusion Matrix Metrics:&quot;</span>)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Confusion Matrix Metrics:&quot;</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>  <span class="fu">print</span>(metrics)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt; $Prevalence</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a><span class="co">#&gt; [1] 0.11524</span></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">#&gt; $Accuracy</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">#&gt; [1] 0.8863083</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co">#&gt; $Sensitivity</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co">#&gt; [1] 0.1573896</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co">#&gt; $Specificity</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a><span class="co">#&gt; [1] 0.98125</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="co">#&gt; $False_Discovery_Rate</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a><span class="co">#&gt; [1] 0.477707</span></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a><span class="co">#&gt; $Diagnostic_Odds_Ratio</span></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a><span class="co">#&gt; [1] 9.775247</span></span></code></pre></div>
<ul>
<li><p>This function calculates key performance metrics:</p></li>
<li><p>Prevalence: Proportion of positive cases in the dataset.</p></li>
<li><p>Accuracy: Overall correct classification rate.</p></li>
<li><p>Sensitivity (Recall): True positive rate.</p></li>
<li><p>Specificity: True negative rate.</p></li>
<li><p>False Discovery Rate: Proportion of false positives among
predicted positives.</p></li>
<li><p>Diagnostic Odds Ratio: A measure of the effectiveness of a
diagnostic test.</p></li>
</ul>
</div>
</div>
</div>
<div id="summary-of-workflow" class="section level2">
<h2>Summary of Workflow</h2>
<p>The <code>logisticreg</code> package simplifies the process of
logistic regression modeling and evaluation. Here’s a step-by-step
summary of the typical workflow:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Generate Data</strong>: Create or load a dataset with
binary response and predictor variables.</p></li>
<li><p><strong>Estimate Coefficients</strong>: Use
<code>estimate_beta()</code> to compute logistic regression coefficients
using numerical optimization.</p></li>
<li><p><strong>Bootstrap Confidence Intervals</strong>: Apply
<code>bootstrap_co_int()</code> to calculate confidence intervals for
the coefficients, providing uncertainty estimates.</p></li>
<li><p><strong>Predict Probabilities</strong>: Use
<code>predicted_prob()</code> to compute the probabilities of the
positive class for each observation.</p></li>
<li><p><strong>Predict Class Labels</strong>: Classify observations
using <code>predict()</code> with a specified probability
cutoff.</p></li>
<li><p><strong>Evaluate Model Performance</strong>: Use
<code>confusion_matrix_metrics()</code> to assess the model’s
performance using metrics like accuracy, sensitivity, and
specificity.</p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
