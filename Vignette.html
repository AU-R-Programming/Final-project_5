<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>logisticreg</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">logisticreg</h1>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Logistic regression is a widely used statistical method for modeling
binary outcomes based on one or more predictor variables. The
<code>logisticreg</code> package provides a streamlined and robust
framework for performing logistic regression using numerical
optimization. This package is designed to help users estimate model
parameters, quantify uncertainty through bootstrap confidence intervals,
and evaluate model performance using comprehensive metrics.</p>
<div id="key-features-of-logisticreg" class="section level3">
<h3>Key Features of <code>logisticreg</code></h3>
<ul>
<li><p><strong>Parameter Estimation</strong>: Uses numerical
optimization (via the <code>optim</code> function) to estimate logistic
regression coefficients efficiently.</p></li>
<li><p><strong>Bootstrap Confidence Intervals</strong>: Provides a
non-parametric approach to assess the uncertainty of estimated
coefficients.</p></li>
<li><p><strong>Prediction</strong>: Includes functions for predicting
probabilities and binary outcomes based on fitted models.</p></li>
<li><p><strong>Performance Evaluation</strong>: Offers tools to
calculate confusion matrices and key performance metrics, such as
accuracy, sensitivity, specificity, and diagnostic odds ratios.</p></li>
</ul>
</div>
<div id="why-use-logisticreg" class="section level3">
<h3>Why Use <code>logisticreg</code>?</h3>
<ul>
<li><p><strong>Customizable Workflows</strong>: Users can easily
integrate their own data and apply the package to various binary
classification tasks.</p></li>
<li><p><strong>Lightweight and Flexible</strong>: Built for R users who
need a quick and effective solution for logistic regression without
relying on large external dependencies.</p></li>
<li><p><strong>Educational Value</strong>: Ideal for understanding
logistic regression concepts and applying them to real-world
datasets.</p></li>
</ul>
<p>This vignette demonstrates the step-by-step use of the
<code>logisticreg</code> package, from estimating coefficients to
evaluating model performance, using a dataset.</p>
</div>
<div id="how-to-use-the-pacakge-and-functions" class="section level3">
<h3>How to Use the Pacakge and Functions</h3>
<p>This vignette provides:</p>
<ol style="list-style-type: decimal">
<li><p>A <strong>workflow example</strong> showing the usage of the
package functions on a dataset.</p></li>
<li><p>Explanations of the key functions included in the
package.</p></li>
<li><p>Insights into interpreting the outputs and evaluating model
performance.</p></li>
</ol>
<p>By the end of this vignette, you’ll have a comprehensive
understanding of how to:</p>
<ol style="list-style-type: decimal">
<li><p>Fit a logistic regression model.</p></li>
<li><p>Interpret the results.</p></li>
<li><p>Evaluate the model’s predictive accuracy and
reliability.</p></li>
</ol>
</div>
</div>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>To get started with the <code>logisticreg</code> package, you first
need to install it from its GitHub repository. The installation process
requires the <code>devtools</code> package, which allows you to install
packages directly from GitHub. If you do not already have
<code>devtools</code> installed, you can install it easily using the
following command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;devtools&quot;</span>)</span></code></pre></div>
<p>Once <code>devtools</code> is installed, you can proceed to install
the <code>logisticreg</code> package. Simply run the following command
in your R console:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;AU-R-Programming/Final-project_5&quot;</span>)</span></code></pre></div>
<p>After successfully installing the <code>logisticreg</code> package,
the next step is to load it into your R environment. Loading the package
ensures that all its functions and features are available for use in
your session. To do this, use the <code>library()</code> function as
shown below:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">library</span>(logisticreg)</span></code></pre></div>
<p>This command activates the package, making its functions accessible
so you can begin your analysis. Once the package is loaded, you can
start exploring its capabilities, such as fitting logistic regression
models, generating predictions, evaluating performance metrics, and
more. Loading the package is a crucial step before running any of its
functionalities.</p>
</div>
<div id="internal-workings-of-logistic_regression_analysis-which-is-the-main-wrapper-function" class="section level2">
<h2>Internal Workings of <code>logistic_regression_analysis()</code>
Which is the Main Wrapper Function</h2>
<p><strong>Description:</strong>
<code>logistic_regression_analysis()</code> orchestrates the entire
logistic regression process: data cleaning, model fitting,
bootstrap-based inference, prediction, and performance evaluation. The
user only needs to provide the data, the predictor names, the response
variable name, and the number of bootstrap samples.</p>
<p><strong>Step-by-Step Process:</strong> 1. <strong>Parameter
Initialization:</strong> - Internally sets the significance level () and
classification cutoff (0.5).</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Data Extraction and Preprocessing:</strong>
<ul>
<li>Subsets the provided data frame to the specified predictors
(<code>x_vars</code>) and response (<code>y_var</code>).</li>
<li>Removes rows with missing values using <code>na.omit()</code> to
ensure a clean dataset for modeling.</li>
<li>Converts character predictors into factors, ensuring categorical
variables are appropriately handled.</li>
<li>Validates and converts the response variable into a binary (0/1)
numeric format.</li>
</ul></li>
<li><strong>Design Matrix Creation:</strong>
<ul>
<li>Calls <code>model.matrix()</code> to construct a design matrix that
includes an intercept and dummy variables for categorical
predictors.</li>
</ul></li>
<li><strong>Coefficient Estimation:</strong>
<ul>
<li>Invokes <code>estimate_beta()</code> to fit the logistic model by
numerically optimizing the log-likelihood function.</li>
<li>Assigns meaningful column names to the estimated coefficients.</li>
</ul></li>
<li><strong>Bootstrap Confidence Intervals:</strong>
<ul>
<li>Uses <code>bootstrap_co_int()</code> to draw multiple bootstrap
samples, refit the model, and compute empirical confidence intervals for
each coefficient.</li>
</ul></li>
<li><strong>Predictions and Probabilities:</strong>
<ul>
<li>Computes predicted probabilities for each observation using
<code>predicted_prob()</code>.</li>
<li>Converts these probabilities into binary class predictions (0/1)
based on the fixed cutoff (0.5).</li>
</ul></li>
<li><strong>Model Performance Evaluation:</strong>
<ul>
<li>Calls <code>confusion_matrix_metrics()</code> to produce a confusion
matrix and performance metrics (accuracy, sensitivity, specificity,
etc.).</li>
<li>Prints key results (coefficients, confidence intervals, predictions,
metrics) to the console for immediate inspection.</li>
</ul></li>
<li><strong>Return Value:</strong>
<ul>
<li>Returns a list containing:
<ul>
<li>Estimated coefficients</li>
<li>Bootstrap confidence intervals</li>
<li>Predicted probabilities</li>
<li>Predicted classes</li>
<li>Confusion matrix metrics</li>
</ul></li>
</ul></li>
</ol>
<p><strong>In Summary:</strong> The function takes care of all the heavy
lifting: from cleaning data and transforming inputs into a suitable
design matrix, to fitting the model, quantifying uncertainty with
bootstrapping, predicting outcomes, and finally assessing how well the
model performed.</p>
<div id="example-workflow" class="section level3">
<h3><strong>Example Workflow</strong></h3>
<p>We will demonstrate the functionality of the package with an example
workflow using the Bank dataset provided.</p>
<div id="information-about-dataset" class="section level4">
<h4>Information about dataset</h4>
<p>The data is related with direct marketing campaigns of a Portuguese
banking institution. The marketing campaigns were based on phone calls.
Often, more than one contact to the same client was required, in order
to access if the product (bank term deposit) would be (‘yes’) or not
(‘no’) subscribed. The classification goal is to predict if the client
will subscribe a term deposit (variable y).</p>
<p>You can access the data from the <a href="https://archive.ics.uci.edu/dataset/222/bank+marketing">UC Irvine
Machine Learning Repository</a></p>
<p><strong>Load the dataset, you can change the path to where you have
the data</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;~/Downloads/bank.csv&quot;</span>, <span class="at">sep =</span> <span class="st">&quot;;&quot;</span>)</span></code></pre></div>
<p>Select the desired columns/predictors you wish to use and create
<code>x_vars</code> and <code>y_var</code></p>
<ul>
<li><strong><em>age</em></strong>: clients age</li>
<li><strong><em>marital</em></strong>: marital status</li>
<li><strong><em>education</em></strong>: education Level</li>
<li><strong><em>default</em></strong>: has credit in default?</li>
<li><strong><em>balance</em></strong>: average yearly balance</li>
<li><strong><em>duration</em></strong>: last contact duration, in
seconds (numeric).</li>
<li><strong><em>previous</em></strong>: number of contacts performed
before this campaign and for this client</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>x_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;age&quot;</span>,  <span class="st">&quot;marital&quot;</span>, <span class="st">&quot;education&quot;</span>, <span class="st">&quot;default&quot;</span>, <span class="st">&quot;balance&quot;</span>,<span class="st">&quot;duration&quot;</span>, <span class="st">&quot;previous&quot;</span>)  <span class="co"># Example predictors</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>y_var <span class="ot">&lt;-</span> <span class="st">&quot;y&quot;</span>  <span class="co"># Response variable</span></span></code></pre></div>
<p>Call the <code>logistic_regression_analysis</code> function, setting
the arguments <code>x_vars</code>, <code>y_var</code> and
<code>no_of_bootstraps</code>.</p>
<ul>
<li>data: A data frame containing the predictors and the response
variable.</li>
<li>x_vars: A character vector specifying the names of the predictor
variables in data.These can be both numeric and categorical variables.
Categorical variables will be internally converted into dummy
variables.</li>
<li>y_var: A character scalar indicating the name of the binary response
variable in data.The response should be coded as 0/1 or as a factor with
two levels.</li>
<li>no_of_bootstraps: An integer specifying the number of bootstrap
samples to use for estimating the confidence intervals of the
coefficients.</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">logistic_regression_analysis</span>(</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>  <span class="at">data =</span> data,</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>  <span class="at">x_vars =</span> x_vars,</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>  <span class="at">y_var =</span> y_var,</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>  <span class="at">no_of_bootstraps =</span> <span class="dv">20</span>  </span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">#&gt; Estimated Coefficients:</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co">#&gt;                             [,1]</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">#&gt; (Intercept)        -3.9861824509</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">#&gt; age                 0.0231161059</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co">#&gt; maritalmarried     -0.6953138026</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="co">#&gt; maritalsingle      -0.3026683861</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">#&gt; educationsecondary  0.5488431414</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">#&gt; educationtertiary   1.1881491302</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">#&gt; educationunknown    1.1227889068</span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="co">#&gt; defaultyes         -1.4411324852</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="co">#&gt; balance            -0.0004205648</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a><span class="co">#&gt; duration            0.0037823035</span></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a><span class="co">#&gt; previous            0.1566433251</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="co">#&gt; attr(,&quot;names&quot;)</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;(Intercept)&quot;        &quot;age&quot;                &quot;maritalmarried&quot;    </span></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a><span class="co">#&gt;  [4] &quot;maritalsingle&quot;      &quot;educationsecondary&quot; &quot;educationtertiary&quot; </span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a><span class="co">#&gt;  [7] &quot;educationunknown&quot;   &quot;defaultyes&quot;         &quot;balance&quot;           </span></span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a><span class="co">#&gt; [10] &quot;duration&quot;           &quot;previous&quot;          </span></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a><span class="co">#&gt; Bootstrap Confidence Intervals:</span></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a><span class="co">#&gt; $lower</span></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a><span class="co">#&gt;  [1] -7.0204367520  0.0183569277 -0.8993089219 -0.5400483416 -0.0915509425</span></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a><span class="co">#&gt;  [6]  0.7213879346 -0.8904984800 -2.4064494121 -0.0005502594  0.0034179017</span></span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a><span class="co">#&gt; [11]  0.1032496669</span></span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a><span class="co">#&gt; $upper</span></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a><span class="co">#&gt;  [1] -3.765467e+00  4.750365e-02  9.023428e-01  1.576808e+00  9.710879e-01</span></span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a><span class="co">#&gt;  [6]  1.574180e+00  1.636710e+00  1.716310e-01 -8.614916e-05  4.541657e-03</span></span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a><span class="co">#&gt; [11]  2.496171e-01</span></span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a><span class="co">#&gt; Predicted Probabilities (first 6):</span></span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a><span class="co">#&gt;         [,1]</span></span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a><span class="co">#&gt; 1 0.01164966</span></span>
<span id="cb6-42"><a href="#cb6-42" tabindex="-1"></a><span class="co">#&gt; 2 0.01935563</span></span>
<span id="cb6-43"><a href="#cb6-43" tabindex="-1"></a><span class="co">#&gt; 3 0.11888505</span></span>
<span id="cb6-44"><a href="#cb6-44" tabindex="-1"></a><span class="co">#&gt; 4 0.06489191</span></span>
<span id="cb6-45"><a href="#cb6-45" tabindex="-1"></a><span class="co">#&gt; 5 0.12853189</span></span>
<span id="cb6-46"><a href="#cb6-46" tabindex="-1"></a><span class="co">#&gt; 6 0.16762340</span></span>
<span id="cb6-47"><a href="#cb6-47" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-48"><a href="#cb6-48" tabindex="-1"></a><span class="co">#&gt; Predictions (first 6):</span></span>
<span id="cb6-49"><a href="#cb6-49" tabindex="-1"></a><span class="co">#&gt;   [,1]</span></span>
<span id="cb6-50"><a href="#cb6-50" tabindex="-1"></a><span class="co">#&gt; 1    0</span></span>
<span id="cb6-51"><a href="#cb6-51" tabindex="-1"></a><span class="co">#&gt; 2    0</span></span>
<span id="cb6-52"><a href="#cb6-52" tabindex="-1"></a><span class="co">#&gt; 3    0</span></span>
<span id="cb6-53"><a href="#cb6-53" tabindex="-1"></a><span class="co">#&gt; 4    0</span></span>
<span id="cb6-54"><a href="#cb6-54" tabindex="-1"></a><span class="co">#&gt; 5    0</span></span>
<span id="cb6-55"><a href="#cb6-55" tabindex="-1"></a><span class="co">#&gt; 6    0</span></span>
<span id="cb6-56"><a href="#cb6-56" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-57"><a href="#cb6-57" tabindex="-1"></a><span class="co">#&gt; Confusion Matrix Metrics:</span></span>
<span id="cb6-58"><a href="#cb6-58" tabindex="-1"></a><span class="co">#&gt; $Prevalence</span></span>
<span id="cb6-59"><a href="#cb6-59" tabindex="-1"></a><span class="co">#&gt; [1] 0.11524</span></span>
<span id="cb6-60"><a href="#cb6-60" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-61"><a href="#cb6-61" tabindex="-1"></a><span class="co">#&gt; $Accuracy</span></span>
<span id="cb6-62"><a href="#cb6-62" tabindex="-1"></a><span class="co">#&gt; [1] 0.8863083</span></span>
<span id="cb6-63"><a href="#cb6-63" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-64"><a href="#cb6-64" tabindex="-1"></a><span class="co">#&gt; $Sensitivity</span></span>
<span id="cb6-65"><a href="#cb6-65" tabindex="-1"></a><span class="co">#&gt; [1] 0.2341651</span></span>
<span id="cb6-66"><a href="#cb6-66" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-67"><a href="#cb6-67" tabindex="-1"></a><span class="co">#&gt; $Specificity</span></span>
<span id="cb6-68"><a href="#cb6-68" tabindex="-1"></a><span class="co">#&gt; [1] 0.97125</span></span>
<span id="cb6-69"><a href="#cb6-69" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-70"><a href="#cb6-70" tabindex="-1"></a><span class="co">#&gt; $False_Discovery_Rate</span></span>
<span id="cb6-71"><a href="#cb6-71" tabindex="-1"></a><span class="co">#&gt; [1] 0.4852321</span></span>
<span id="cb6-72"><a href="#cb6-72" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-73"><a href="#cb6-73" tabindex="-1"></a><span class="co">#&gt; $Diagnostic_Odds_Ratio</span></span>
<span id="cb6-74"><a href="#cb6-74" tabindex="-1"></a><span class="co">#&gt; [1] 10.32952</span></span></code></pre></div>
</div>
</div>
</div>
<div id="interpretation-of-results" class="section level2">
<h2>Interpretation of Results</h2>
<p><strong>Model Coefficients:</strong> - The intercept is negative and
large in magnitude, indicating a low baseline probability of a positive
outcome when all predictors are at their reference levels. - Positive
coefficients (e.g., for <code>educationtertiary</code>) suggest that
having that characteristic increases the likelihood of a positive
outcome. - Negative coefficients (e.g., for <code>defaultyes</code>)
indicate that having that trait decreases the likelihood of a positive
outcome.</p>
<p><strong>Bootstrap Confidence Intervals:</strong> - The provided
intervals show the range of plausible values for each coefficient. -
Many intervals do not include zero, suggesting that those predictors
have a meaningful association with the outcome.</p>
<p><strong>Predicted Probabilities and Predictions:</strong> - The first
six predicted probabilities are all relatively low (&lt;0.17), leading
to predicted class 0 for these observations. - This suggests the model
is conservative about predicting positive outcomes.</p>
<p><strong>Performance Metrics:</strong></p>
<ul>
<li><strong>Prevalence (~0.115):</strong> About 11.5% of observations
are positive in the dataset.</li>
<li><strong>Accuracy (~0.886):</strong> The model correctly classifies
nearly 89% of observations overall.</li>
<li><strong>Sensitivity (~0.234):</strong> It correctly identifies about
23% of actual positives, indicating it often misses positives.</li>
<li><strong>Specificity (~0.971):</strong> It correctly identifies about
97% of actual negatives, showing strong performance in ruling out
negatives.</li>
<li><strong>False Discovery Rate (~0.485):</strong> Almost half of the
predicted positives are actually false positives.</li>
<li><strong>Diagnostic Odds Ratio (10.33):</strong> The model has
moderate ability to distinguish between positive and negative
cases.</li>
</ul>
</div>
<div id="documentation-of-helper-functions" class="section level2">
<h2>Documentation of Helper Functions</h2>
<p>Below is a description of the main helper functions included in the
package. These functions work together to perform logistic regression
estimation using numerical optimization, bootstrap confidence intervals,
and model performance evaluation.</p>
<div id="log_likelihoodbeta-x-y" class="section level3">
<h3>1. <code>log_likelihood(beta, X, y)</code></h3>
<p><strong>Description:</strong><br />
Calculates the negative log-likelihood for a given set of parameters
(<code>beta</code>), predictors (<code>X</code>), and binary response
(<code>y</code>). This function is internally used by the optimization
routine to find the parameter values that minimize the negative
log-likelihood.</p>
<p><strong>Key Details:</strong><br />
- <code>beta</code>: Coefficient vector for the logistic regression
model.<br />
- <code>X</code>: Design matrix of predictors (including intercept if
applicable).<br />
- <code>y</code>: Binary response variable (0/1).<br />
- Ensures numerical stability by clipping probabilities away from 0 and
1 with a small <code>epsilon</code>.</p>
</div>
<div id="estimate_betax-y" class="section level3">
<h3>2. <code>estimate_beta(X, y)</code></h3>
<p><strong>Description:</strong><br />
Estimates the logistic regression coefficients by minimizing the
negative log-likelihood using the <code>optim()</code> function. It
starts from an initial guess derived from a least-squares approximation
and iteratively updates the parameters.</p>
<p><strong>Key Details:</strong><br />
- <code>X</code>: Design matrix of predictors.<br />
- <code>y</code>: Binary response variable.<br />
- Returns a vector of estimated coefficients that best fit the data
under a logistic model.</p>
</div>
<div id="bootstrap_co_intx-y-alpha-0.05-no_of_bootstraps-20" class="section level3">
<h3>3.
<code>bootstrap_co_int(X, y, alpha = 0.05, no_of_bootstraps = 20)</code></h3>
<p><strong>Description:</strong><br />
Computes bootstrap confidence intervals for the estimated coefficients.
It repeatedly samples the data with replacement, re-estimates the
coefficients, and then derives empirical percentile-based confidence
intervals.</p>
<p><strong>Key Details:</strong><br />
- <code>X</code>: Design matrix of predictors.<br />
- <code>y</code>: Binary response variable.<br />
- <code>alpha</code>: Significance level (default 0.05).<br />
- <code>no_of_bootstraps</code>: Number of bootstrap samples (default
20).<br />
- Returns a list with <code>lower</code> and <code>upper</code>
confidence limits for each coefficient.</p>
</div>
<div id="predicted_probbeta-x" class="section level3">
<h3>4. <code>predicted_prob(beta, X)</code></h3>
<p><strong>Description:</strong><br />
Generates the predicted probabilities of the positive class (1) for each
observation given the current coefficient estimates.</p>
<p><strong>Key Details:</strong><br />
- <code>beta</code>: Coefficient vector.<br />
- <code>X</code>: Design matrix.<br />
- Returns a vector of probabilities (values between 0 and 1).</p>
</div>
<div id="predictlabelsbeta-x-cutoff-0.5" class="section level3">
<h3>5. <code>predictlabels(beta, X, cutoff = 0.5)</code></h3>
<p><strong>Description:</strong><br />
Converts predicted probabilities into class predictions (0 or 1) based
on a specified cutoff. Observations with predicted probabilities above
the cutoff are classified as 1; otherwise, 0.</p>
<p><strong>Key Details:</strong><br />
- <code>beta</code>: Coefficient vector.<br />
- <code>X</code>: Design matrix.<br />
- <code>cutoff</code>: Classification threshold (default 0.5).<br />
- Returns a vector of predicted classes (0/1).</p>
</div>
<div id="confusion_matrix_metricsy_true-y_pred" class="section level3">
<h3>6. <code>confusion_matrix_metrics(y_true, y_pred)</code></h3>
<p><strong>Description:</strong><br />
Calculates various performance metrics derived from the confusion
matrix. This includes accuracy, sensitivity, specificity, false
discovery rate, and diagnostic odds ratio, among others.</p>
<p><strong>Key Details:</strong><br />
- <code>y_true</code>: True binary labels.<br />
- <code>y_pred</code>: Predicted binary labels.<br />
- Returns a list of performance metrics and summary statistics.</p>
<hr />
<p><strong>How These Functions Work Together:</strong> -
<code>log_likelihood()</code> and <code>estimate_beta()</code> handle
the core parameter estimation for logistic regression. -
<code>bootstrap_co_int()</code> refines the understanding of parameter
uncertainty through resampling. - <code>predicted_prob()</code> and
<code>predictlabels()</code> translate model parameters into
interpretable predictions. - <code>confusion_matrix_metrics()</code>
provides a snapshot of how well the model’s predictions align with the
actual outcomes, guiding model evaluation and comparison.</p>
<p>You will not need to call these helper functions directly if you use
the main wrapper function (ie,
<code>logistic_regression_analysis()</code>). However, understanding
these components can help you diagnose issues, customize analyses, or
extend the functionality.</p>
<p><strong>The <code>logisticreg</code> package simplifies the process
of logistic regression modeling and evaluation.</strong></p>
</div>
</div>
<div id="logistic-regression-shiny-app" class="section level2">
<h2>Logistic Regression Shiny App</h2>
<p>This Shiny app provides an interactive interface for performing
logistic regression analysis. Upload your dataset, select the response
and predictor variables, and view the results instantly.</p>
<p>To launch the app, simply run the following command in your R
console:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">run_logisticreg_app</span>()</span></code></pre></div>
</div>
<div id="github-repository" class="section level2">
<h2>Github Repository</h2>
<p>Thank you for exploring the logisticreg package! This package aims to
simplify logistic regression modeling and provide robust tools for data
analysis. For detailed documentation, examples, and the source code,
please visit the <a href="https://github.com/AU-R-Programming/Final-project_5">GitHub
repository</a> Your feedback and contributions are always welcome!</p>
<div id="dedicated-website" class="section level3">
<h3>Dedicated Website</h3>
<p>You can also find everything in this document on our dedicated
website, where it’s conveniently organized and easy to navigate. <a href="https://au-r-programming.github.io/Final-project_5/">Visit our
website for a seamless experience and additional resources!</a></p>
</div>
<div id="references" class="section level3">
<h3>References</h3>
<p>We would like to acknowledge the contributions of generative language
models, which played a role in enhancing the clarity and quality of this
project and documentation. These tools helped in refining our
explanations and improving the overall presentation of the package’s
features. You can find our conversations <a href="https://chatgpt.com/share/6753730b-3d58-8005-9a30-ac98f3060ce2">here</a>
and <a href="https://chatgpt.com/share/6753674f-aa38-800a-b218-c6ebf5d03349">here</a>.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
